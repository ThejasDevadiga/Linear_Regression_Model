Linear Regression
In linear regression problems, the goal is to predict a real-value variable y from a given pattern X. In the case of linear regression the output is a linear function of the input. Letŷ be the output our model predicts: ŷ = WX+b

Here X is a vector (features of an example), W are the weights (vector of parameters) that determine how each feature affects the prediction andb is bias term. So our task T is to predict y from X, now we need to measure performance P to know how well the model performs.

Now to calculate the performance of the model, we first calculate the error of each example i as:

Ei = abs(Yi^-Yi)

we take the absolute value of the error to take into account both positive and negative values of error.

Finally we calculate the mean for all recorded absolute errors (Average sum of all absolute errors).

Mean Absolute Error (MAE) = Average of All absolute errors

MAE = 1/m TOTAL_SUM(abs(Yi^-Yi))


Mean Squared Error (MSE): Average of squared differences between prediction and actual observation.


MSE = 1/2m TOTAL_SUM(abs(Yi^-Yi)^2)


The main aim of training the ML algorithm is to adjust the weights W to reduce the MAE or MSE.

To minimize the error, the model while experiencing the examples of the training set, updates the model parameters W. These error calculations when plotted against the W is also called cost function J(w), since it determines the cost/penalty of the model. So minimizing the error is also called as minimization the cost function J.


Gradient descent Algorithm:
When we plot the cost function J(w) vs w. It is represented as below:


As we see from the curve, there exists a value of parameters W which has the minimum cost Jmin. Now we need to find a way to reach this minimum cost.

In the gradient descent algorithm, we start with random model parameters and calculate the error for each learning iteration, keep updating the model parameters to move closer to the values that results in minimum cost.


repeat until minimum cost: {
        Wj = Wj - alpha* changeIn(J(W) wrt(Wj)
}


In the above equation we are updating the model parameters after each iteration. The second term of the equation calculates the slope or gradient of the curve at each iteration.

The gradient of the cost function is calculated as partial derivative of cost function J with respect to each model parameter wj, j takes value of number of features [1 to n]. α, alpha, is the learning rate, or how quickly we want to move towards the minimum. If α is too large, we can overshoot. If α is too small, means small steps of learning hence the overall time taken by the model to observe all examples will be more.


here are three ways of doing gradient descent:

Batch gradient descent: Uses all of the training instances to update the model parameters in each iteration.

Mini-batch Gradient Descent: Instead of using all examples, Mini-batch Gradient Descent divides the training set into smaller size called batch denoted by ‘b’. Thus a mini-batch ‘b’ is used to update the model parameters in each iteration.

Stochastic Gradient Descent (SGD): updates the parameters using only a single training instance in each iteration. The training instance is usually selected randomly. Stochastic gradient descent is often preferred to optimize cost functions when there are hundreds of thousands of training instances or more, as it will converge more quickly than batch gradient descent [3].

